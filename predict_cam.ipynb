{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import CamembertTokenizerFast, CamembertForSequenceClassification, Trainer\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "LABEL_NAMES = ['scolomfr-voc-015-num-1179',\n",
    " 'scolomfr-voc-015-num-1548',\n",
    " 'scolomfr-voc-015-num-1032',\n",
    " 'scolomfr-voc-015-num-1333',\n",
    " 'scolomfr-voc-015-num-6360',\n",
    " 'scolomfr-voc-015-num-980',\n",
    " 'scolomfr-voc-015-num-1430',\n",
    " 'scolomfr-voc-015-num-919',\n",
    " 'scolomfr-voc-015-num-7755',\n",
    " 'scolomfr-voc-015-num-1831',\n",
    " 'scolomfr-voc-015-num-6364',\n",
    " 'scolomfr-voc-015-num-1832',\n",
    " 'scolomfr-voc-015-num-6365',\n",
    " 'scolomfr-voc-015-num-1834',\n",
    " 'scolomfr-voc-015-num-6369',\n",
    " 'scolomfr-voc-015-num-7816']\n",
    "\n",
    "MODEL_PATH = '/home/joachim/gdrive/domain-helper/results/checkpoint-10000'\n",
    "\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(\"camembert-base\")\n",
    "\n",
    "\n",
    "X_test_tokenized = tokenizer(['Entrée littéraire et culturelle : le monstre aux limites de l’humain.'], padding=True, truncation=True)\n",
    "\n",
    "dataset = Dataset(X_test_tokenized)\n",
    "# Load trained model\n",
    "model = CamembertForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=len(LABEL_NAMES))\n",
    "\n",
    "# Define test trainer\n",
    "test_trainer = Trainer(model)\n",
    "\n",
    "# Make prediction\n",
    "raw_pred, a, b = test_trainer.predict(dataset)\n",
    "\n",
    "# Preprocess raw predictions\n",
    "Y_pred = np.argmax(raw_pred, axis=1)[0]\n",
    "\n",
    "print(LABEL_NAMES[Y_pred])"
   ],
   "metadata": {
    "id": "-bGBcDg7QNq6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scolomfr-voc-015-num-1333\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "colab": {
   "name": "training_cam.ipynb",
   "provenance": [],
   "machine_shape": "hm",
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}